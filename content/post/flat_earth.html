---
title: "Lost in Transformation: The Horror and Wonder of Logit"
subtitle: "Once You See What Logit Is, You'll Love It Too"
author: "Robert Kubinec and Sujeong Shim"
date: "2023-09-25T15:00:00"
output: blogdown::html_page
header:
  title: "Lost in Transformation: The Mystery and the Wonder of Logit"
  summary: "The logit model for binary outcomes is poorly understood because it involves thinking in non-linear spaces. In this post, I illustrate what logit is using maps--and why people who resist logit are a bit like flat earthers."
  image: "headers/map_header.jpg"
  date: "2024-04-09T00:00:00"
tags: ["R", "Statistics", "Proportions"]
categories: ["R"]
---



<p>Perhaps no other subject in applied statistics and machine learning has caused people as much trouble as the humble logit model. Most people who learn either subject start off with some form of linear regression, and having grasped it, are then told that if they have a variable with only two values, none of the rules apply. Horror of horrors: logit is a <em>non-linear</em> model, a doom from which few escape unscathed. Interpreting logit coefficients is a fraught exercise as not only applied researchers but also statisticians have endless arguments about how this should be done.</p>
<p>In this post I de-mystify logit—and show why it’s such a useful model—by using maps. Yes, non-linear spaces can be tricky to understand, but as humans we can think reasonably well in up to three dimensions. If you know what the difference between a map and a globe is, then you can run and interpret logit just fine.</p>
<p>I’m also going to argue based on this analogy that people who assiduously avoid logit are not so dissimilar from flat earthers. It’s true that moving from a map to a globe induces additional complications, but the alternative is run into <em>significant</em> problems in navigation. Similarly, applying the workhouse OLS model to a binary outcome isn’t wrong, but it can lead you astray when you want to figure out the distance between two points. Once you read this post, I hope you’ll see why logit is not all that complicated and should be the preferred model with a binary outcome.</p>
<div id="b-is-for-bernoulli" class="section level2">
<h2>B Is For Bernoulli</h2>
<p>I’ll start first with a review of what a logit model actually is and there is some confusion on this score. Logit is actually the wrong name for what most people are estimating; the model is in fact the Bernoulli distribution. This distribution has the following form for a variable <span class="math inline">\(Y\)</span> that takes on two values, i.e. 0 or 1:</p>
<p><span class="math display">\[
P(Y = k) = \begin{cases} p, &amp; \text{if } k=1, \\1-p, &amp; \text{if } k=0. \end{cases}
\]</span></p>
<p>As soon as the math appears, of course, it looks complicated. This formula is actually the simplest statistical distribution once you break it down. What it says is that, on average, the probability that a variable <span class="math inline">\(Y\)</span> is equal to 1 is determined by the parameter <span class="math inline">\(p\)</span>, which represents a probability or a proportion. Suppose that <span class="math inline">\(Y\)</span> has 10 values, 30% of which are zeroes (0s) and 70% of which are 1s. In that case, <span class="math inline">\(p\)</span> would be equal to 0.7 or 70% because 70% of the time <span class="math inline">\(Y\)</span> is equal to 1. The probability of 0s is then <span class="math inline">\(1-p\)</span> or 100% - 70% = 30%. Easy peezy.</p>
<p>What is important to remember, though, is that <span class="math inline">\(p\)</span> is a proportion, so it can’t be greater than 1 or less than 0. (That’s why the Bernoulli and Beta distributions are connected, which I discuss in my other <a href="https://www.robertkubinec.com/post/limited_dvs/">post on the topic</a>). You can’t have <span class="math inline">\(Y\)</span> be equal to 1 more than 100% of the time or less than 0% of the time; that’s nonsensical.</p>
<p>You’ve probably noticed that so far we haven’t mentioned the word “logit” at all. Where does this tricky little monster come in?</p>
<p>Well if all we want to do is calculate the average proportion of 1s in <span class="math inline">\(Y\)</span> then all we need is <span class="math inline">\(p\)</span>. But what if we want to see if there is a relationship between some covariate <span class="math inline">\(X\)</span>, say how old a person is, and a binary variable like <span class="math inline">\(Y\)</span>? For example, suppose we want to know if older people are more likely to vote for Biden: voting can take on two values, either voting (1) or not voting (0). As an example, I’ll generate some plausible-looking age data a bunch of citizens that we’ll call our covariate <span class="math inline">\(X\)</span>:</p>
<p><img src="/post/flat_earth_files/figure-html/age-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We see that the average person in our data is about 45 years old and the age range is between roughly 20 and 60. What we want to understand is whether on average older (or younger) people tend to vote for Biden. But we have a problem - <span class="math inline">\(p\)</span> in the Bernoulli distribution cannot be any bigger than 1 or less than 0, but our age variable <span class="math inline">\(X\)</span> goes from 20 to 70. Yikes! We can’t just pop <span class="math inline">\(X\)</span> into <span class="math inline">\(p\)</span> and see what happens.</p>
<p>If you take a look at <span class="math inline">\(X\)</span>, you might think, “OK, well, just divide <span class="math inline">\(X\)</span> by 100 and it’ll be between 0 and 1.” Great thought! Let’s do that and plot <span class="math inline">\(X\)</span> again:</p>
<p><img src="/post/flat_earth_files/figure-html/age2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We just squashed <span class="math inline">\(X\)</span> to be small enough that we could just pop it into the Bernoulli distribution:</p>
<p><span class="math display">\[
P(Y = k) = \begin{cases} X, &amp; \text{if } k=1, \\1-X, &amp; \text{if } k=0. \end{cases}
\]</span></p>
<p>Here we simply replaced <span class="math inline">\(p\)</span> with our covariate <span class="math inline">\(X\)</span>. Very nice! We can even generate random data using a simple algorithm from this function:</p>
<ol style="list-style-type: decimal">
<li><p>Draw a random number between 0 and 1.</p></li>
<li><p>If the random number is greater than <span class="math inline">\(X\)</span>, set <span class="math inline">\(Y\)</span> equal to 1, and 0 otherwise.</p></li>
</ol>
<p>Here’s what our random data <span class="math inline">\(Y\)</span> look like compared to <span class="math inline">\(X\)</span>:</p>
<p><img src="/post/flat_earth_files/figure-html/simXY-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>What our plot shows is that when X is high, we tend to get more 1s in <span class="math inline">\(Y\)</span>, and when <span class="math inline">\(X\)</span> is low, we tend to get more 0s. The blue line shows what the average value of <span class="math inline">\(Y\)</span> is for a given age. When age is quite high, about 0.65 or 65 years, then <span class="math inline">\(Y\)</span> is about 0.65 or 65% on average (as we expect given the 1:1 relationship).</p>
<p>If you look at this formula, though, you might think something is a bit off. Do we think that someone’s age as a fraction will be exactly equal to their probability of voting for Biden? Will voters who are 70 years old have an exactly 70% chance of voting for him? We only have one option for describing that relationship, and a 1:1 correspondence seems very limiting. So what do we do if we think this relationship is more nuanced?</p>
<p>To allow the relationship to be less exact, we’ll take a page out of linear regression and add a coefficient to multiply <span class="math inline">\(X\)</span>, which we’ll call <span class="math inline">\(\beta\)</span>. We’ll add <span class="math inline">\(\beta\)</span> to our little formula:</p>
<p><span class="math display">\[
P(Y = k) = \begin{cases} \beta X, &amp; \text{if } k=1, \\1-\beta X, &amp; \text{if } k=0. \end{cases}
\]</span></p>
<p>Now let’s say <span class="math inline">\(\beta\)</span> is equal to 0.5. Then, the probability that someone will vote for Biden if they are 70 years old is only 35%. If <span class="math inline">\(\beta\)</span> goes up, then that relationship would be stronger. Adding a coefficient allows us to express the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> with a lot more nuance.</p>
<p>You might see some further issues, though. What if <span class="math inline">\(\beta\)</span> is equal to 0? In that case, the probability that someone votes for Biden is also equal to exactly 0%. In probability world, that’s not a good thing—we can’t be 100% certain that someone will or will not vote for Biden. We’ll get around this problem by adding another parameter called the intercept, <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
P(Y = k) = \begin{cases} \alpha + \beta X, &amp; \text{if } k=1, \\1-(\alpha + \beta X), &amp; \text{if } k=0. \end{cases}
\]</span></p>
<p>This is a handy dandy trick to allow <span class="math inline">\(\beta\)</span> to equal 0 without having the probability of <span class="math inline">\(Y\)</span> to be equal to 0 as well. Say <span class="math inline">\(\alpha\)</span> is 0.35--then if <span class="math inline">\(\beta\)</span> is 0, 35% of people would still vote Biden. <span class="math inline">\(\alpha\)</span> could be thought of as a baseline rate—without considering the effect of age, how many people vote for Biden? Once we add <span class="math inline">\(\alpha\)</span>, this equation is the same as the slope of a line (good ol’ <span class="math inline">\(mx + b\)</span>), which makes it a <em>linear</em> model (linear means a straight line).</p>
<p>We now have a linear model we want to stick in <span class="math inline">\(p\)</span> to model the relationship between age (<span class="math inline">\(X\)</span>) and voting for Biden (<span class="math inline">\(Y\)</span>). We’ve made progress, but we’re still gonna have issues squashing <span class="math inline">\(X\)</span> into a proportion. The trick is that we need <span class="math inline">\(\alpha + \beta X\)</span> to always output a number between 0 and 1. We can’t have a proportion greater than 1 or less than 0. For these reasons, to use this model we have to pick specific values for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> that allow us to keep within those bounds. For example, we could set <span class="math inline">\(\alpha\)</span> to 0.1 (a baseline rate of 10% of 1s) and <span class="math inline">\(\beta\)</span> to 0.3. Let’s simulate some data with those numbers and plot it:</p>
<p><img src="/post/flat_earth_files/figure-html/sim_mod-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We now have a much weaker relationship between age and voting: voting for Biden increases a bit as people age, but not much. But we do now have a much more nuanced relationship than we started out with by using the divide by 100 method. Very cool!</p>
<p>However, you might be wondering—what if we want even more diverse relationships? What if <span class="math inline">\(\beta\)</span> were greater than 1? Or 3? Or 10? Let’s plot what happens when we set <span class="math inline">\(\alpha\)</span> = 0.1 and <span class="math inline">\(\beta\)</span>=3:</p>
<p><img src="/post/flat_earth_files/figure-html/sim_mod2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Yikes! Now we’re only getting values for <span class="math inline">\(Y\)</span> that are equal to 1. What happened to all the 0s? When we multiply <span class="math inline">\(X\)</span> by 3, we now get values way bigger than 100%. For an age of 50, <span class="math inline">\(X/100\)</span> = 0.5, and <span class="math inline">\(3\cdot X=1.5\)</span> or 150%. Shucks! This means we can’t just pick whatever values we want for <span class="math inline">\(\beta\)</span> or <span class="math inline">\(\alpha\)</span>. That’s frustrating especially if we think that relationship could be really strong and we want <span class="math inline">\(\beta\)</span> to be large.</p>
</div>
<div id="not-all-heroes-are-linear" class="section level2">
<h2>Not All Heroes Are Linear</h2>
<p>We now have two options. We can keep on guessing what values might work for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, or… we could get a map. A map that would allow us to <em>translate</em> or <em>transform</em> our linear model <span class="math inline">\(\alpha + \beta X\)</span> into the cramped space of <span class="math inline">\(p\)</span>. Like the teleporter in Star Trek, we need something that can move our value of <span class="math inline">\(\alpha + \beta X\)</span> to the right spot on <span class="math inline">\(p\)</span> without going over 1 and under 0.</p>
<p>This is where our good friend logit comes in. Logit is a function that can take in <em>any</em> number–literally any number–and <em>magically</em> transform it to a number that is strictly between 0 and 1. It’s a magical map that let’s us move from the world of ages and to the world of proportions between 0 and 1.</p>
<p>The function itself is a bit ugly, but I’ll include it here along with our linear model as the input and <span class="math inline">\(p\)</span> as the output:</p>
<p><span class="math display">\[
p = \frac{1}{1 + e^{-(\alpha + \beta X)}}
\]</span></p>
<p>I won’t spend a lot of time on explaining the function other than to note that it has the number <span class="math inline">\(e\)</span>, which is where a lot of the magic comes from. We can test whether it can really do these transformations by plotting a range of numbers for our linear model and seeing what the logit function spits out:</p>
<p><img src="/post/flat_earth_files/figure-html/logitsim-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>On the bottom you can see all the values for our linear model when <span class="math inline">\(\alpha=-10\)</span> and <span class="math inline">\(\beta=0.2\)</span>. Across the range of ages, the linear model runs from -2.5 to 2.5 or way outside the bounds of <span class="math inline">\(p\)</span>. But our logit function spits out a number for <span class="math inline">\(p\)</span> that is between 0 and 1. It also has this cool bend-y shape, or what’s known as a sigmoid. Basically, the line is straight or linear right around the midpoint of <span class="math inline">\(p\)</span> or 0.5. When it gets close to the end points of <span class="math inline">\(p\)</span>, or proportions that are very high or very low, it starts to bend like a driver avoiding a barrier in a car.</p>
<p>If you notice, though, while the line curves, it never changes the direction. When the linear model goes up, so does <span class="math inline">\(p\)</span>. That’s why we can use this function–we will learn about the direction and magnitude of the relationship between age and voting. We just learn that information while respecting the bounds of proportions <strong>and</strong> the full range of our covariates. Pretty cool!</p>
</div>
<div id="a-whole-new-world" class="section level2">
<h2>A Whole New World</h2>
<p>Often people get confused or suspicious at this point. What’s up with this weird S-curve thing? Linear models are nice and straight. Why do we need the bend-y thing?</p>
<p>To understand this, we can return back to our analogies of maps. The maps that we use are all two-dimensional: we can put them on a table and they lie flat. However, we know that they aren’t completely accurate because the earth is not flat, it’s round. A globe is the truly accurate representation of the earth. A flattened map is going to inevitably cause distortions.</p>
<p>As a result, when we trace a flight path on a flat map, the plane’s journey is always curved as in the picture below:</p>
<p><img src="flight_route.gif" /></p>
<p>This flight path–which happens to be for a very long flight from Paris to Tahiti–seems bizarrely roundabout on the map. You would think that the straightest path between Paris and Tahiti would be a straight line. This would be true <em>if the Earth were flat, but it’s not</em>. The Earth is round, and the map is a <em>linear</em> projection of a 3-D object onto a 2-D surface. When we do that and calculate the most direct route, we end up with this weird bend-y shape: <em>just like our logit plot above</em>.</p>
<p>By the same analogy, our linear model is our simplified version of reality that allows us to understand the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Logit is the <em>transformation</em> that takes us from this simplified world to the real world of <span class="math inline">\(Y\)</span> via <span class="math inline">\(p\)</span>. It does that by warping the space that the straight line of our linear model travels. To see this, let’s take another look at our logit plot:</p>
<p><img src="/post/flat_earth_files/figure-html/logitsim2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>When the linear model is 0–or <span class="math inline">\(p\)</span> is around 0.5–the logit function allows <span class="math inline">\(p\)</span> to change relatively quickly as the linear model changes. However, when the linear model gets very low or very high–i.e., <span class="math inline">\(p\)</span> is close to 0 or 1–the logit function only lets <span class="math inline">\(p\)</span> change slowly as the linear model changes. To get from a <span class="math inline">\(p\)</span> of 0.1 to almost 0 requires the linear model to move about -2 points on the <span class="math inline">\(x\)</span> axis, but to get from a <span class="math inline">\(p\)</span> of 0.5 to a <span class="math inline">\(p\)</span> of 0.25 only requires a movement of about -0.5 in the linear model space.</p>
<p>The magical part of logit is that it creates more space as the linear model gets very big or very small. The linear model keeps moving at the same rate (<span class="math inline">\(\beta\)</span>) but <span class="math inline">\(p\)</span>, the proportion, does not. <span class="math inline">\(p\)</span> slows down as though more and more space kept appearing. Like Jim Carrey in the Truman Show who can never escape from his artificial world, the linear model can never escape the bounds of <span class="math inline">\(p\)</span>. The closer it gets to the bounds, the farther it has to travel–the more warped the linear model space becomes relative to <span class="math inline">\(p\)</span>. In other words, at the edges the linear model map is less accurate and so we see a stronger bend in the logit function to compensate.</p>
</div>
<div id="flat-earthers-and-the-logit-function" class="section level2">
<h2>Flat Earthers and the Logit Function</h2>
<p>What is logit then? A handy dandy <em>scaling</em> function that maps a linear model to a proportion between 0 and 1. That’s all it does. The actual distribution is the Bernoulli (though sadly, no one calls it that). A logit function isn’t special—there are other similar functions, just as there are a lot of map coordinate transformations (talk to a GIS person sometime; it’ll bore you to tears).</p>
<p>There are people who <em>really</em> don’t like logit. Usually it’s something to do with how the function complicates things and makes these bend-y shapes. It does require some thinking as we have to think a bit about what our linear model coefficient <span class="math inline">\(\beta\)</span> means. The linear model is a straight line, but the space it is passing through changes as <span class="math inline">\(p\)</span> changes. What that means substantively is that <span class="math inline">\(\beta\)</span>, or the effect of age on the proportion voting for Biden, <em>will vary depending on how big or small the proportion voting for Biden is</em>. If that proportion is small, a big value of <span class="math inline">\(\beta\)</span> will result in much smaller movement in voting than when the proportion voting is closer to 50%.</p>
<p>It is this bend-y (or non-linear) nature of logit that leads some people to just ignore the Bernoulli and use a linear model. That is an easy way to deal with the problem, but unfortunately, we cannot simply ignore this transformation. Like flat earthers, if we ignore the fact that the earth is round, we won’t be able to calculate distances accurately. If we have a linear model that can get larger or smaller than 0% or 100%, then we will end up with nonsensical predictions from our linear model like a plane that ends up at the wrong airport because the pilot believed the Earth was flat.</p>
<p>So how do you interpret a logit model coefficients? There are two ways once you understand what the logit function does:</p>
<ol style="list-style-type: decimal">
<li>Leave it as it is. The coefficient <span class="math inline">\(\beta\)</span> is the relationship of the covariate (<span class="math inline">\(X\)</span>) to the outcome (<span class="math inline">\(Y\)</span>) in the linear or “flat” space. The larger <span class="math inline">\(\beta\)</span> is, the stronger the relationship is between the covariate and the outcome. No, we don’t know exactly how much the proportion will change as <span class="math inline">\(X\)</span> changes, but we can still interpret <span class="math inline">\(\beta\)</span> as expressing what that change looks like in the simple space of the linear model.</li>
<li>Convert it to changes in <span class="math inline">\(Y\)</span> via the proportion <span class="math inline">\(p\)</span>. Just like a plane figuring out distances using transformation of coordinates, we can figure out the average change in a proportion <span class="math inline">\(p\)</span> by averaging (or marginalizing) over different logit functions for a given <span class="math inline">\(\beta\)</span>. I won’t go into the technical details, but we have very handy R packages to calculate what are called <em>marginal effects:</em> how much does the “real world” <span class="math inline">\(p\)</span> change as our linear model coefficient <span class="math inline">\(\beta\)</span> changes?</li>
</ol>
<p>There are plenty of vignettes about how to calculate marginal effects on the R package <code>marginaleffects</code> <a href="https://marginaleffects.com/vignettes/slopes.html">website</a>. Here I’ll show how to calculate a marginal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> with our linear model coefficients of <span class="math inline">\(\alpha=-10\)</span> and <span class="math inline">\(\beta=0.2\)</span>. To do so I’ll first simulate data with these values and then fit a logit (i.e. Bernoulli) model with the R function <code>glm</code>:</p>
<pre><code>## 
## Call:
## glm(formula = Y ~ X, family = binomial(link = &quot;logit&quot;), data = sim_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2091  -0.7986  -0.4686   0.8678   2.5201  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -9.78933    0.70117  -13.96   &lt;2e-16 ***
## X            0.19578    0.01484   13.20   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1250.71  on 999  degrees of freedom
## Residual deviance:  998.47  on 998  degrees of freedom
## AIC: 1002.5
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Above we see the output of the <code>glm</code> command that shows us the values of <span class="math inline">\(\alpha\)</span> (the intercept, as noted in the command output) and <span class="math inline">\(\beta\)</span>, which is listed as the <code>Estimate</code> for <code>X</code>. These are the values of these parameters <em>in the linear</em>, or simple, space. There is nothing wrong with these coefficients: they tell you how much <span class="math inline">\(X\)</span> is changing with respect to <span class="math inline">\(Y\)</span> in the linear space. How much actual change in <span class="math inline">\(Y\)</span> happens, though, depends on exactly where we are (or how high or low the proportion of 1s is in <span class="math inline">\(Y\)</span>).</p>
<p>If we want to convert these relationships to the distances/effects in the outcome <span class="math inline">\(Y\)</span> (i.e. changes in the proportion <span class="math inline">\(p\)</span>), we can use the <code>avg_slopes</code> function from <code>marginaleffects</code>:</p>
<pre><code>## 
##  Term Estimate Std. Error    z Pr(&gt;|z|)  2.5 % 97.5 %
##     X   0.0324    0.00158 20.5   &lt;0.001 0.0293 0.0355
## 
## Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high</code></pre>
<p>Note that this <code>Estimate</code> is way smaller than the <code>Estimate</code> for <span class="math inline">\(\beta\)</span> from the <code>glm</code> command. That estimate was from the linear space and so is much bigger. The <code>marginaleffects</code> command is telling us how much <span class="math inline">\(p\)</span>, or the proportion of 1s in <span class="math inline">\(Y\)</span>, changed as our covariate <span class="math inline">\(X\)</span> increased. It did this by averaging over different logit functions given changes in <span class="math inline">\(X\)</span> (you can see the package info for more technical details). On average, as age increased by 1 year, the proportion voting for Biden increased by 0.0325 or 3.25% with a confidence interval of (2.93%, 3.56%).</p>
<p>Very cool! Now that you understand logit models and how to interpret linear model coefficients in both the linear space and via marginal effects, you know pretty much everything you need to know about this wonderful little function logit. Next time you have a binary outcome like voting for Biden, or anything else, give logit a go! It’s your map to a whole new world.</p>
<div class="tenor-gif-embed" data-postid="19525174" data-share-method="host" data-aspect-ratio="1.77778" data-width="100%">
<a href="https://tenor.com/view/all-by-myself-jasmine-gif-19525174">All By Myself Jasmine GIF</a>from <a href="https://tenor.com/search/all+by+myself-gifs">All By Myself GIFs</a>
</div>
<script type="text/javascript" async src="https://tenor.com/embed.js"></script>
</div>
